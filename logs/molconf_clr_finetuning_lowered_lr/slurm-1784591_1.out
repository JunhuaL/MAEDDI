Job running on landonia09
Job started: 06/03/2024 21:52:43
Setting up bash environment
Activating conda environment: masters
Running provided command: python molconf_finetuning.py --configfile=./configs/MolConfConfigs/4_molconf_config_allcls.yml
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[21:53:43] SMILES Parse Error: syntax error while parsing: OC1=CC=CC(=C1)C-1=C2\CCC(=N2)\C(=C2/N\C(\C=C2)=C(/C2=N/C(/C=C2)=C(\C2=CC=C\-1N2)C1=CC(O)=CC=C1)C1=CC(O)=CC=C1)\C1=CC(O)=CC=C1
[21:53:43] SMILES Parse Error: Failed parsing SMILES 'OC1=CC=CC(=C1)C-1=C2\CCC(=N2)\C(=C2/N\C(\C=C2)=C(/C2=N/C(/C=C2)=C(\C2=CC=C\-1N2)C1=CC(O)=CC=C1)C1=CC(O)=CC=C1)\C1=CC(O)=CC=C1' for input: 'OC1=CC=CC(=C1)C-1=C2\CCC(=N2)\C(=C2/N\C(\C=C2)=C(/C2=N/C(/C=C2)=C(\C2=CC=C\-1N2)C1=CC(O)=CC=C1)C1=CC(O)=CC=C1)\C1=CC(O)=CC=C1'
[21:53:43] Explicit valence for atom # 0 N, 4, is greater than permitted
[21:53:43] Explicit valence for atom # 0 N, 4, is greater than permitted
[21:53:43] Explicit valence for atom # 0 N, 4, is greater than permitted
[21:53:43] Explicit valence for atom # 0 N, 4, is greater than permitted
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type     | Params
-----------------------------------
0 | model | DeepDrug | 1.1 M 
-----------------------------------
1.1 M     Trainable params
0         Non-trainable params
1.1 M     Total params
4.576     Total estimated model params size (MB)
Metric val_epoch_F1 improved. New best score: 0.692
Metric val_epoch_F1 improved by 0.004 >= min_delta = 0.001. New best score: 0.695
Metric val_epoch_F1 improved by 0.007 >= min_delta = 0.001. New best score: 0.702
Metric val_epoch_F1 improved by 0.003 >= min_delta = 0.001. New best score: 0.705
Metric val_epoch_F1 improved by 0.002 >= min_delta = 0.001. New best score: 0.708
Metric val_epoch_F1 improved by 0.002 >= min_delta = 0.001. New best score: 0.709
Metric val_epoch_F1 improved by 0.002 >= min_delta = 0.001. New best score: 0.711
Monitored metric val_epoch_F1 did not improve in the last 10 records. Best score: 0.711. Signaling Trainer to stop.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Namespace(configfile='./configs/MolConfConfigs/4_molconf_config_allcls.yml')
{'dataset': 'DrugBank', 'task': 'binary', 'category': 'DDI', 'entry1_file': './dataset/DrugBank/drug/processed/data.pt', 'entry2_file': './dataset/DrugBank/drug/processed/data.pt', 'entry1_seq_file': './dataset/DrugBank/drug/drug.csv', 'pair_file': './dataset/DrugBank/binary_1vs1/entry_pairs.csv', 'label_file': './dataset/DrugBank/binary_1vs1/pair_labels.csv', 'save_folder': './output/mol_conf/DrugBank/binary_1vs1/all_cluster/', 'split_strategy': 'sample_from_all_clusters', 'gconv_ckpt': './model_checkpoints/molconf_epoch_20_layers_4_random/last.ckpt', 'lin_eval': False, 'model_type': 'deepdrug', 'gpus': 0, 'num_out_dim': 1, 'n_layers': 4, 'n_confs': 1, 'lr': 1e-05}
print parameters:
{
  "earlystopping_tracking": "val_epoch_F1",
  "entry1_data_folder": "./dataset/DrugBank/drug",
  "entry1_seq_file": "./dataset/DrugBank/drug/drug.csv",
  "entry2_data_folder": "./dataset/DrugBank/drug",
  "entry2_seq_file": null,
  "entry_pairs_file": "./dataset/DrugBank/binary_1vs1/entry_pairs.csv",
  "gpus": 0,
  "model_type": "deepdrug",
  "pair_labels_file": "./dataset/DrugBank/binary_1vs1/pair_labels.csv",
  "save_folder": "./output/mol_conf/DrugBank/binary_1vs1/all_cluster/",
  "scheduler_ReduceLROnPlateau_tracking": "F1",
  "split_strat": "sample_from_all_clusters",
  "task_type": "binary",
  "y_pred_file": "./output/mol_conf/DrugBank/binary_1vs1/all_cluster/test_pred.csv",
  "y_transfrom_func": null,
  "y_true_file": "./output/mol_conf/DrugBank/binary_1vs1/all_cluster/test_true.csv"
}
DeepDrug(
  (gconv1): DeeperGCN(
    (node_encoder): Sequential(
      (0): Linear(in_features=121, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (gcn_blocks): ModuleList(
      (0): ModuleList(
        (0): DeepGCNLayerV2(block=res+)
        (1): DeepGCNLayerV2(block=res+)
        (2): DeepGCNLayerV2(block=res+)
        (3): DeepGCNLayerV2(block=res+)
      )
    )
  )
  (gconv1_conf): DeeperGCN(
    (node_encoder): Sequential(
      (0): Linear(in_features=14, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (gcn_blocks): ModuleList(
      (0): ModuleList(
        (0): DeepGCNLayerV2(block=res+)
        (1): DeepGCNLayerV2(block=res+)
        (2): DeepGCNLayerV2(block=res+)
        (3): DeepGCNLayerV2(block=res+)
      )
    )
    (edge_encoder): Sequential(
      (0): Linear(in_features=6, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (gconv2_conf): DeeperGCN(
    (node_encoder): Sequential(
      (0): Linear(in_features=14, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (gcn_blocks): ModuleList(
      (0): ModuleList(
        (0): DeepGCNLayerV2(block=res+)
        (1): DeepGCNLayerV2(block=res+)
        (2): DeepGCNLayerV2(block=res+)
        (3): DeepGCNLayerV2(block=res+)
      )
    )
    (edge_encoder): Sequential(
      (0): Linear(in_features=6, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (gconv2): DeeperGCN(
    (node_encoder): Sequential(
      (0): Linear(in_features=121, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (gcn_blocks): ModuleList(
      (0): ModuleList(
        (0): DeepGCNLayerV2(block=res+)
        (1): DeepGCNLayerV2(block=res+)
        (2): DeepGCNLayerV2(block=res+)
        (3): DeepGCNLayerV2(block=res+)
      )
    )
  )
  (global_fc_nn): Sequential(
    (0): Linear(in_features=512, out_features=128, bias=True)
    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=False)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=32, bias=True)
    (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Dropout(p=0.2, inplace=False)
    (7): ReLU()
  )
  (fc2): Linear(in_features=32, out_features=1, bias=True)
)
CLRModel(
  (mol_encoder): DeeperGCN(
    (node_encoder): Sequential(
      (0): Linear(in_features=121, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (gcn_blocks): ModuleList(
      (0): ModuleList(
        (0): DeepGCNLayerV2(block=res+)
        (1): DeepGCNLayerV2(block=res+)
        (2): DeepGCNLayerV2(block=res+)
        (3): DeepGCNLayerV2(block=res+)
      )
    )
  )
  (conf_encoder): DeeperGCN(
    (node_encoder): Sequential(
      (0): Linear(in_features=14, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (gcn_blocks): ModuleList(
      (0): ModuleList(
        (0): DeepGCNLayerV2(block=res+)
        (1): DeepGCNLayerV2(block=res+)
        (2): DeepGCNLayerV2(block=res+)
        (3): DeepGCNLayerV2(block=res+)
      )
    )
    (edge_encoder): Sequential(
      (0): Linear(in_features=6, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (feat_lin): Linear(in_features=256, out_features=128, bias=True)
  (out_lin): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=128, out_features=64, bias=True)
  )
)
CLRModel(
  (mol_encoder): DeeperGCN(
    (node_encoder): Sequential(
      (0): Linear(in_features=121, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (gcn_blocks): ModuleList(
      (0): ModuleList(
        (0): DeepGCNLayerV2(block=res+)
        (1): DeepGCNLayerV2(block=res+)
        (2): DeepGCNLayerV2(block=res+)
        (3): DeepGCNLayerV2(block=res+)
      )
    )
  )
  (conf_encoder): DeeperGCN(
    (node_encoder): Sequential(
      (0): Linear(in_features=14, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (gcn_blocks): ModuleList(
      (0): ModuleList(
        (0): DeepGCNLayerV2(block=res+)
        (1): DeepGCNLayerV2(block=res+)
        (2): DeepGCNLayerV2(block=res+)
        (3): DeepGCNLayerV2(block=res+)
      )
    )
    (edge_encoder): Sequential(
      (0): Linear(in_features=6, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (feat_lin): Linear(in_features=256, out_features=128, bias=True)
  (out_lin): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=128, out_features=64, bias=True)
  )
)
preparing dataset...
loading processed data...
add degrees as node features for each sample...
using drug sequences file: ./dataset/DrugBank/drug
loading processed data...
add degrees as node features for each sample...
the order of entryIDs are not the same in dataset 1 & 2 .
checking entryIDs finished for MultiEmbedDataset_v1.
loading processed data...
add degrees as node features for each sample...
using target sequences file: ./dataset/DrugBank/drug
loading processed data...
add degrees as node features for each sample...
the order of entryIDs are not the same in dataset 1 & 2 .
checking entryIDs finished for MultiEmbedDataset_v1.
can not find cv_file,  sample_from_all_clusters ...
0.6456154854372742
0.12866422668302624
0.22572028787969955
in val dataloader...

val:Ep0000|| F1: 1.000,auROC nan,auPRC: 1.000
in train dataloader...

val:Ep0000|| F1: 0.692,auROC 0.674,auPRC: 0.658

trn:Ep0000|| F1: 0.634,auROC 0.600,auPRC: 0.572

val:Ep0001|| F1: 0.695,auROC 0.685,auPRC: 0.670

trn:Ep0001|| F1: 0.643,auROC 0.649,auPRC: 0.621

val:Ep0002|| F1: 0.702,auROC 0.698,auPRC: 0.683

trn:Ep0002|| F1: 0.654,auROC 0.672,auPRC: 0.642

val:Ep0003|| F1: 0.702,auROC 0.707,auPRC: 0.692

trn:Ep0003|| F1: 0.664,auROC 0.688,auPRC: 0.660

val:Ep0004|| F1: 0.705,auROC 0.714,auPRC: 0.699

trn:Ep0004|| F1: 0.670,auROC 0.698,auPRC: 0.672

val:Ep0005|| F1: 0.704,auROC 0.717,auPRC: 0.702

trn:Ep0005|| F1: 0.677,auROC 0.709,auPRC: 0.683

val:Ep0006|| F1: 0.705,auROC 0.723,auPRC: 0.709

trn:Ep0006|| F1: 0.681,auROC 0.717,auPRC: 0.692

val:Ep0007|| F1: 0.708,auROC 0.726,auPRC: 0.711

trn:Ep0007|| F1: 0.686,auROC 0.724,auPRC: 0.701

val:Ep0008|| F1: 0.700,auROC 0.733,auPRC: 0.717
Epoch 00010: reducing learning rate of group 0 to 1.0000e-06.

trn:Ep0008|| F1: 0.690,auROC 0.731,auPRC: 0.708

val:Ep0009|| F1: 0.709,auROC 0.733,auPRC: 0.717

trn:Ep0009|| F1: 0.693,auROC 0.736,auPRC: 0.714

val:Ep0010|| F1: 0.709,auROC 0.733,auPRC: 0.718

trn:Ep0010|| F1: 0.695,auROC 0.738,auPRC: 0.715

val:Ep0011|| F1: 0.711,auROC 0.734,auPRC: 0.718

trn:Ep0011|| F1: 0.694,auROC 0.738,auPRC: 0.717

val:Ep0012|| F1: 0.710,auROC 0.734,auPRC: 0.718

trn:Ep0012|| F1: 0.696,auROC 0.740,auPRC: 0.718

val:Ep0013|| F1: 0.711,auROC 0.734,auPRC: 0.719

trn:Ep0013|| F1: 0.696,auROC 0.739,auPRC: 0.717

val:Ep0014|| F1: 0.709,auROC 0.735,auPRC: 0.719

trn:Ep0014|| F1: 0.696,auROC 0.740,auPRC: 0.719

val:Ep0015|| F1: 0.711,auROC 0.736,auPRC: 0.721

trn:Ep0015|| F1: 0.696,auROC 0.740,auPRC: 0.719

val:Ep0016|| F1: 0.711,auROC 0.736,auPRC: 0.721

trn:Ep0016|| F1: 0.696,auROC 0.742,auPRC: 0.719

val:Ep0017|| F1: 0.712,auROC 0.736,auPRC: 0.720
Epoch 00019: reducing learning rate of group 0 to 1.0000e-07.

trn:Ep0017|| F1: 0.697,auROC 0.742,auPRC: 0.720

val:Ep0018|| F1: 0.711,auROC 0.736,auPRC: 0.721

trn:Ep0018|| F1: 0.697,auROC 0.743,auPRC: 0.722

val:Ep0019|| F1: 0.712,auROC 0.735,auPRC: 0.720

trn:Ep0019|| F1: 0.697,auROC 0.743,auPRC: 0.721

val:Ep0020|| F1: 0.711,auROC 0.736,auPRC: 0.721

trn:Ep0020|| F1: 0.697,auROC 0.743,auPRC: 0.721

val:Ep0021|| F1: 0.712,auROC 0.736,auPRC: 0.721
loading best weight in /home/s1950841/MAEDDI/output/mol_conf/DrugBank/binary_1vs1/all_cluster/models/epoch=21-step=21208.ckpt ...
DeepDrug(
  (gconv1): DeeperGCN(
    (node_encoder): Sequential(
      (0): Linear(in_features=121, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (gcn_blocks): ModuleList(
      (0): ModuleList(
        (0): DeepGCNLayerV2(block=res+)
        (1): DeepGCNLayerV2(block=res+)
        (2): DeepGCNLayerV2(block=res+)
        (3): DeepGCNLayerV2(block=res+)
      )
    )
  )
  (gconv1_conf): DeeperGCN(
    (node_encoder): Sequential(
      (0): Linear(in_features=14, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (gcn_blocks): ModuleList(
      (0): ModuleList(
        (0): DeepGCNLayerV2(block=res+)
        (1): DeepGCNLayerV2(block=res+)
        (2): DeepGCNLayerV2(block=res+)
        (3): DeepGCNLayerV2(block=res+)
      )
    )
    (edge_encoder): Sequential(
      (0): Linear(in_features=6, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (gconv2_conf): DeeperGCN(
    (node_encoder): Sequential(
      (0): Linear(in_features=14, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (gcn_blocks): ModuleList(
      (0): ModuleList(
        (0): DeepGCNLayerV2(block=res+)
        (1): DeepGCNLayerV2(block=res+)
        (2): DeepGCNLayerV2(block=res+)
        (3): DeepGCNLayerV2(block=res+)
      )
    )
    (edge_encoder): Sequential(
      (0): Linear(in_features=6, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (gconv2): DeeperGCN(
    (node_encoder): Sequential(
      (0): Linear(in_features=121, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (gcn_blocks): ModuleList(
      (0): ModuleList(
        (0): DeepGCNLayerV2(block=res+)
        (1): DeepGCNLayerV2(block=res+)
        (2): DeepGCNLayerV2(block=res+)
        (3): DeepGCNLayerV2(block=res+)
      )
    )
  )
  (global_fc_nn): Sequential(
    (0): Linear(in_features=512, out_features=128, bias=True)
    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=False)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=32, bias=True)
    (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Dropout(p=0.2, inplace=False)
    (7): ReLU()
  )
  (fc2): Linear(in_features=32, out_features=1, bias=True)
)
in test dataloader...

tst:Ep0022|| F1: 0.707,auROC 0.737,auPRC: 0.703
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
       Test metric             DataLoader 0
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
        test_loss           0.6213921904563904
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
in test dataloader...
save prediction completed.
Command ran successfully!

============
job finished successfully
Job finished: 06/03/2024 23:43:10
