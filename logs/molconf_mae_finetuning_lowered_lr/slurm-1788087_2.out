Job running on landonia08
Job started: 12/03/2024 15:47:31
Setting up bash environment
Activating conda environment: masters
Running provided command: python molconf_finetuning.py --configfile=./configs/MolConfConfigs/mae/4_molconf_config_allcls.yml
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[15:49:45] SMILES Parse Error: syntax error while parsing: OC1=CC=CC(=C1)C-1=C2\CCC(=N2)\C(=C2/N\C(\C=C2)=C(/C2=N/C(/C=C2)=C(\C2=CC=C\-1N2)C1=CC(O)=CC=C1)C1=CC(O)=CC=C1)\C1=CC(O)=CC=C1
[15:49:45] SMILES Parse Error: Failed parsing SMILES 'OC1=CC=CC(=C1)C-1=C2\CCC(=N2)\C(=C2/N\C(\C=C2)=C(/C2=N/C(/C=C2)=C(\C2=CC=C\-1N2)C1=CC(O)=CC=C1)C1=CC(O)=CC=C1)\C1=CC(O)=CC=C1' for input: 'OC1=CC=CC(=C1)C-1=C2\CCC(=N2)\C(=C2/N\C(\C=C2)=C(/C2=N/C(/C=C2)=C(\C2=CC=C\-1N2)C1=CC(O)=CC=C1)C1=CC(O)=CC=C1)\C1=CC(O)=CC=C1'
[15:49:45] Explicit valence for atom # 0 N, 4, is greater than permitted
[15:49:46] Explicit valence for atom # 0 N, 4, is greater than permitted
[15:49:46] Explicit valence for atom # 0 N, 4, is greater than permitted
[15:49:46] Explicit valence for atom # 0 N, 4, is greater than permitted
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type     | Params
-----------------------------------
0 | model | DeepDrug | 1.1 M 
-----------------------------------
1.1 M     Trainable params
0         Non-trainable params
1.1 M     Total params
4.576     Total estimated model params size (MB)
Metric val_epoch_F1 improved. New best score: 0.671
Metric val_epoch_F1 improved by 0.007 >= min_delta = 0.001. New best score: 0.678
Metric val_epoch_F1 improved by 0.002 >= min_delta = 0.001. New best score: 0.680
Metric val_epoch_F1 improved by 0.004 >= min_delta = 0.001. New best score: 0.683
Metric val_epoch_F1 improved by 0.002 >= min_delta = 0.001. New best score: 0.685
Metric val_epoch_F1 improved by 0.001 >= min_delta = 0.001. New best score: 0.686
Metric val_epoch_F1 improved by 0.003 >= min_delta = 0.001. New best score: 0.689
Metric val_epoch_F1 improved by 0.001 >= min_delta = 0.001. New best score: 0.690
Metric val_epoch_F1 improved by 0.002 >= min_delta = 0.001. New best score: 0.692
Monitored metric val_epoch_F1 did not improve in the last 10 records. Best score: 0.692. Signaling Trainer to stop.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Namespace(configfile='./configs/MolConfConfigs/mae/4_molconf_config_allcls.yml')
{'dataset': 'DrugBank', 'task': 'binary', 'category': 'DDI', 'entry1_file': './dataset/DrugBank/drug/processed/data.pt', 'entry2_file': './dataset/DrugBank/drug/processed/data.pt', 'entry1_seq_file': './dataset/DrugBank/drug/drug.csv', 'pair_file': './dataset/DrugBank/binary_1vs1/entry_pairs.csv', 'label_file': './dataset/DrugBank/binary_1vs1/pair_labels.csv', 'save_folder': './output/mol_conf/mae/DrugBank/binary_1vs1/all_cluster/', 'split_strategy': 'sample_from_all_clusters', 'gconv_ckpt': './model_checkpoints/molconf_mae_epoch_20_layers_4_random/last.ckpt', 'lin_eval': False, 'model_type': 'deepdrug', 'gpus': 0, 'num_out_dim': 1, 'n_layers': 4, 'n_confs': 1, 'lr': 1e-05}
print parameters:
{
  "earlystopping_tracking": "val_epoch_F1",
  "entry1_data_folder": "./dataset/DrugBank/drug",
  "entry1_seq_file": "./dataset/DrugBank/drug/drug.csv",
  "entry2_data_folder": "./dataset/DrugBank/drug",
  "entry2_seq_file": null,
  "entry_pairs_file": "./dataset/DrugBank/binary_1vs1/entry_pairs.csv",
  "gpus": 0,
  "model_type": "deepdrug",
  "pair_labels_file": "./dataset/DrugBank/binary_1vs1/pair_labels.csv",
  "save_folder": "./output/mol_conf/mae/DrugBank/binary_1vs1/all_cluster/",
  "scheduler_ReduceLROnPlateau_tracking": "F1",
  "split_strat": "sample_from_all_clusters",
  "task_type": "binary",
  "y_pred_file": "./output/mol_conf/mae/DrugBank/binary_1vs1/all_cluster/test_pred.csv",
  "y_transfrom_func": null,
  "y_true_file": "./output/mol_conf/mae/DrugBank/binary_1vs1/all_cluster/test_true.csv"
}
DeepDrug(
  (gconv1): DeeperGCN(
    (node_encoder): Sequential(
      (0): Linear(in_features=121, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (gcn_blocks): ModuleList(
      (0): ModuleList(
        (0): DeepGCNLayerV2(block=res+)
        (1): DeepGCNLayerV2(block=res+)
        (2): DeepGCNLayerV2(block=res+)
        (3): DeepGCNLayerV2(block=res+)
      )
    )
  )
  (gconv1_conf): DeeperGCN(
    (node_encoder): Sequential(
      (0): Linear(in_features=14, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (gcn_blocks): ModuleList(
      (0): ModuleList(
        (0): DeepGCNLayerV2(block=res+)
        (1): DeepGCNLayerV2(block=res+)
        (2): DeepGCNLayerV2(block=res+)
        (3): DeepGCNLayerV2(block=res+)
      )
    )
    (edge_encoder): Sequential(
      (0): Linear(in_features=6, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (gconv2_conf): DeeperGCN(
    (node_encoder): Sequential(
      (0): Linear(in_features=14, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (gcn_blocks): ModuleList(
      (0): ModuleList(
        (0): DeepGCNLayerV2(block=res+)
        (1): DeepGCNLayerV2(block=res+)
        (2): DeepGCNLayerV2(block=res+)
        (3): DeepGCNLayerV2(block=res+)
      )
    )
    (edge_encoder): Sequential(
      (0): Linear(in_features=6, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (gconv2): DeeperGCN(
    (node_encoder): Sequential(
      (0): Linear(in_features=121, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (gcn_blocks): ModuleList(
      (0): ModuleList(
        (0): DeepGCNLayerV2(block=res+)
        (1): DeepGCNLayerV2(block=res+)
        (2): DeepGCNLayerV2(block=res+)
        (3): DeepGCNLayerV2(block=res+)
      )
    )
  )
  (global_fc_nn): Sequential(
    (0): Linear(in_features=512, out_features=128, bias=True)
    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=False)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=32, bias=True)
    (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Dropout(p=0.2, inplace=False)
    (7): ReLU()
  )
  (fc2): Linear(in_features=32, out_features=1, bias=True)
)
MAEModel(
  (mol_encoder): DeeperGCN(
    (node_encoder): Sequential(
      (0): Linear(in_features=121, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (gcn_blocks): ModuleList(
      (0): ModuleList(
        (0): DeepGCNLayerV2(block=res+)
        (1): DeepGCNLayerV2(block=res+)
        (2): DeepGCNLayerV2(block=res+)
        (3): DeepGCNLayerV2(block=res+)
      )
    )
  )
  (mol_decoder): DeeperGCN(
    (node_encoder): Sequential(
      (0): Linear(in_features=128, out_features=121, bias=True)
      (1): LayerNorm((121,), eps=1e-05, elementwise_affine=True)
    )
    (gcn_blocks): ModuleList(
      (0): ModuleList(
        (0): DeepGCNLayerV2(block=res+)
      )
    )
  )
  (conf_encoder): DeeperGCN(
    (node_encoder): Sequential(
      (0): Linear(in_features=14, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (gcn_blocks): ModuleList(
      (0): ModuleList(
        (0): DeepGCNLayerV2(block=res+)
        (1): DeepGCNLayerV2(block=res+)
        (2): DeepGCNLayerV2(block=res+)
        (3): DeepGCNLayerV2(block=res+)
      )
    )
    (edge_encoder): Sequential(
      (0): Linear(in_features=6, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (conf_decoder): DeeperGCN(
    (node_encoder): Sequential(
      (0): Linear(in_features=128, out_features=14, bias=True)
      (1): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
    )
    (gcn_blocks): ModuleList(
      (0): ModuleList(
        (0): DeepGCNLayerV2(block=res+)
      )
    )
    (edge_encoder): Sequential(
      (0): Linear(in_features=128, out_features=6, bias=True)
      (1): LayerNorm((6,), eps=1e-05, elementwise_affine=True)
    )
    (edge_decoder): Linear(in_features=14, out_features=6, bias=True)
  )
  (enc2dec_mol_nodes): Linear(in_features=128, out_features=128, bias=False)
  (enc2dec_conf_nodes): Linear(in_features=128, out_features=128, bias=False)
  (enc2dec_conf_edges): Linear(in_features=128, out_features=128, bias=False)
)
MAEModel(
  (mol_encoder): DeeperGCN(
    (node_encoder): Sequential(
      (0): Linear(in_features=121, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (gcn_blocks): ModuleList(
      (0): ModuleList(
        (0): DeepGCNLayerV2(block=res+)
        (1): DeepGCNLayerV2(block=res+)
        (2): DeepGCNLayerV2(block=res+)
        (3): DeepGCNLayerV2(block=res+)
      )
    )
  )
  (mol_decoder): DeeperGCN(
    (node_encoder): Sequential(
      (0): Linear(in_features=128, out_features=121, bias=True)
      (1): LayerNorm((121,), eps=1e-05, elementwise_affine=True)
    )
    (gcn_blocks): ModuleList(
      (0): ModuleList(
        (0): DeepGCNLayerV2(block=res+)
      )
    )
  )
  (conf_encoder): DeeperGCN(
    (node_encoder): Sequential(
      (0): Linear(in_features=14, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (gcn_blocks): ModuleList(
      (0): ModuleList(
        (0): DeepGCNLayerV2(block=res+)
        (1): DeepGCNLayerV2(block=res+)
        (2): DeepGCNLayerV2(block=res+)
        (3): DeepGCNLayerV2(block=res+)
      )
    )
    (edge_encoder): Sequential(
      (0): Linear(in_features=6, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (conf_decoder): DeeperGCN(
    (node_encoder): Sequential(
      (0): Linear(in_features=128, out_features=14, bias=True)
      (1): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
    )
    (gcn_blocks): ModuleList(
      (0): ModuleList(
        (0): DeepGCNLayerV2(block=res+)
      )
    )
    (edge_encoder): Sequential(
      (0): Linear(in_features=128, out_features=6, bias=True)
      (1): LayerNorm((6,), eps=1e-05, elementwise_affine=True)
    )
    (edge_decoder): Linear(in_features=14, out_features=6, bias=True)
  )
  (enc2dec_mol_nodes): Linear(in_features=128, out_features=128, bias=False)
  (enc2dec_conf_nodes): Linear(in_features=128, out_features=128, bias=False)
  (enc2dec_conf_edges): Linear(in_features=128, out_features=128, bias=False)
)
preparing dataset...
loading processed data...
add degrees as node features for each sample...
using drug sequences file: ./dataset/DrugBank/drug
loading processed data...
add degrees as node features for each sample...
the order of entryIDs are not the same in dataset 1 & 2 .
checking entryIDs finished for MultiEmbedDataset_v1.
loading processed data...
add degrees as node features for each sample...
using target sequences file: ./dataset/DrugBank/drug
loading processed data...
add degrees as node features for each sample...
the order of entryIDs are not the same in dataset 1 & 2 .
checking entryIDs finished for MultiEmbedDataset_v1.
can not find cv_file,  sample_from_all_clusters ...
0.6436167568797859
0.1245778209149677
0.23180542220524641
in val dataloader...

val:Ep0000|| F1: 0.916,auROC nan,auPRC: 1.000
in train dataloader...

val:Ep0000|| F1: 0.671,auROC 0.656,auPRC: 0.618

trn:Ep0000|| F1: 0.615,auROC 0.599,auPRC: 0.569

val:Ep0001|| F1: 0.678,auROC 0.674,auPRC: 0.632

trn:Ep0001|| F1: 0.632,auROC 0.651,auPRC: 0.619

val:Ep0002|| F1: 0.677,auROC 0.672,auPRC: 0.630

trn:Ep0002|| F1: 0.641,auROC 0.663,auPRC: 0.631

val:Ep0003|| F1: 0.679,auROC 0.676,auPRC: 0.634

trn:Ep0003|| F1: 0.644,auROC 0.669,auPRC: 0.635

val:Ep0004|| F1: 0.680,auROC 0.680,auPRC: 0.638

trn:Ep0004|| F1: 0.646,auROC 0.674,auPRC: 0.640

val:Ep0005|| F1: 0.683,auROC 0.683,auPRC: 0.640

trn:Ep0005|| F1: 0.649,auROC 0.678,auPRC: 0.646

val:Ep0006|| F1: 0.685,auROC 0.688,auPRC: 0.647

trn:Ep0006|| F1: 0.654,auROC 0.686,auPRC: 0.654

val:Ep0007|| F1: 0.679,auROC 0.692,auPRC: 0.650

trn:Ep0007|| F1: 0.660,auROC 0.693,auPRC: 0.661

val:Ep0008|| F1: 0.686,auROC 0.697,auPRC: 0.655
Epoch 00010: reducing learning rate of group 0 to 1.0000e-06.

trn:Ep0008|| F1: 0.661,auROC 0.693,auPRC: 0.661

val:Ep0009|| F1: 0.689,auROC 0.693,auPRC: 0.650

trn:Ep0009|| F1: 0.664,auROC 0.700,auPRC: 0.669

val:Ep0010|| F1: 0.690,auROC 0.697,auPRC: 0.656

trn:Ep0010|| F1: 0.665,auROC 0.700,auPRC: 0.668

val:Ep0011|| F1: 0.683,auROC 0.695,auPRC: 0.653

trn:Ep0011|| F1: 0.664,auROC 0.698,auPRC: 0.666

val:Ep0012|| F1: 0.690,auROC 0.696,auPRC: 0.657

trn:Ep0012|| F1: 0.666,auROC 0.702,auPRC: 0.672

val:Ep0013|| F1: 0.680,auROC 0.699,auPRC: 0.657

trn:Ep0013|| F1: 0.667,auROC 0.703,auPRC: 0.672

val:Ep0014|| F1: 0.689,auROC 0.693,auPRC: 0.651

trn:Ep0014|| F1: 0.668,auROC 0.703,auPRC: 0.672

val:Ep0015|| F1: 0.684,auROC 0.700,auPRC: 0.658

trn:Ep0015|| F1: 0.670,auROC 0.706,auPRC: 0.676

val:Ep0016|| F1: 0.692,auROC 0.692,auPRC: 0.651

trn:Ep0016|| F1: 0.669,auROC 0.706,auPRC: 0.676

val:Ep0017|| F1: 0.682,auROC 0.700,auPRC: 0.658
Epoch 00019: reducing learning rate of group 0 to 1.0000e-07.

trn:Ep0017|| F1: 0.669,auROC 0.705,auPRC: 0.674

val:Ep0018|| F1: 0.689,auROC 0.700,auPRC: 0.658

trn:Ep0018|| F1: 0.671,auROC 0.707,auPRC: 0.676

val:Ep0019|| F1: 0.685,auROC 0.701,auPRC: 0.659

trn:Ep0019|| F1: 0.669,auROC 0.706,auPRC: 0.676

val:Ep0020|| F1: 0.682,auROC 0.700,auPRC: 0.658

trn:Ep0020|| F1: 0.669,auROC 0.708,auPRC: 0.677

val:Ep0021|| F1: 0.684,auROC 0.700,auPRC: 0.658

trn:Ep0021|| F1: 0.670,auROC 0.707,auPRC: 0.677

val:Ep0022|| F1: 0.687,auROC 0.700,auPRC: 0.657

trn:Ep0022|| F1: 0.671,auROC 0.707,auPRC: 0.677

val:Ep0023|| F1: 0.688,auROC 0.701,auPRC: 0.659

trn:Ep0023|| F1: 0.669,auROC 0.706,auPRC: 0.676

val:Ep0024|| F1: 0.683,auROC 0.700,auPRC: 0.659

trn:Ep0024|| F1: 0.670,auROC 0.707,auPRC: 0.677

val:Ep0025|| F1: 0.685,auROC 0.702,auPRC: 0.660

trn:Ep0025|| F1: 0.669,auROC 0.707,auPRC: 0.676

val:Ep0026|| F1: 0.687,auROC 0.701,auPRC: 0.659
Epoch 00028: reducing learning rate of group 0 to 1.0000e-08.
loading best weight in /home/s1950841/MAEDDI/output/mol_conf/mae/DrugBank/binary_1vs1/all_cluster/models/epoch=16-step=16354.ckpt ...
DeepDrug(
  (gconv1): DeeperGCN(
    (node_encoder): Sequential(
      (0): Linear(in_features=121, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (gcn_blocks): ModuleList(
      (0): ModuleList(
        (0): DeepGCNLayerV2(block=res+)
        (1): DeepGCNLayerV2(block=res+)
        (2): DeepGCNLayerV2(block=res+)
        (3): DeepGCNLayerV2(block=res+)
      )
    )
  )
  (gconv1_conf): DeeperGCN(
    (node_encoder): Sequential(
      (0): Linear(in_features=14, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (gcn_blocks): ModuleList(
      (0): ModuleList(
        (0): DeepGCNLayerV2(block=res+)
        (1): DeepGCNLayerV2(block=res+)
        (2): DeepGCNLayerV2(block=res+)
        (3): DeepGCNLayerV2(block=res+)
      )
    )
    (edge_encoder): Sequential(
      (0): Linear(in_features=6, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (gconv2_conf): DeeperGCN(
    (node_encoder): Sequential(
      (0): Linear(in_features=14, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (gcn_blocks): ModuleList(
      (0): ModuleList(
        (0): DeepGCNLayerV2(block=res+)
        (1): DeepGCNLayerV2(block=res+)
        (2): DeepGCNLayerV2(block=res+)
        (3): DeepGCNLayerV2(block=res+)
      )
    )
    (edge_encoder): Sequential(
      (0): Linear(in_features=6, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (gconv2): DeeperGCN(
    (node_encoder): Sequential(
      (0): Linear(in_features=121, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (gcn_blocks): ModuleList(
      (0): ModuleList(
        (0): DeepGCNLayerV2(block=res+)
        (1): DeepGCNLayerV2(block=res+)
        (2): DeepGCNLayerV2(block=res+)
        (3): DeepGCNLayerV2(block=res+)
      )
    )
  )
  (global_fc_nn): Sequential(
    (0): Linear(in_features=512, out_features=128, bias=True)
    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=False)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=32, bias=True)
    (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Dropout(p=0.2, inplace=False)
    (7): ReLU()
  )
  (fc2): Linear(in_features=32, out_features=1, bias=True)
)
in test dataloader...

tst:Ep0027|| F1: 0.709,auROC 0.717,auPRC: 0.703
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
       Test metric             DataLoader 0
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
        test_loss           0.6577398180961609
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
in test dataloader...
save prediction completed.
Command ran successfully!

============
job finished successfully
Job finished: 12/03/2024 18:02:05
