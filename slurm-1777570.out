Job running on landonia18
Job started: 05/02/2024 13:48:41
Setting up bash environment
Activating conda environment: masters
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[13:50:00] SMILES Parse Error: syntax error while parsing: OC1=CC=CC(=C1)C-1=C2\CCC(=N2)\C(=C2/N\C(\C=C2)=C(/C2=N/C(/C=C2)=C(\C2=CC=C\-1N2)C1=CC(O)=CC=C1)C1=CC(O)=CC=C1)\C1=CC(O)=CC=C1
[13:50:00] SMILES Parse Error: Failed parsing SMILES 'OC1=CC=CC(=C1)C-1=C2\CCC(=N2)\C(=C2/N\C(\C=C2)=C(/C2=N/C(/C=C2)=C(\C2=CC=C\-1N2)C1=CC(O)=CC=C1)C1=CC(O)=CC=C1)\C1=CC(O)=CC=C1' for input: 'OC1=CC=CC(=C1)C-1=C2\CCC(=N2)\C(=C2/N\C(\C=C2)=C(/C2=N/C(/C=C2)=C(\C2=CC=C\-1N2)C1=CC(O)=CC=C1)C1=CC(O)=CC=C1)\C1=CC(O)=CC=C1'
[13:50:01] Explicit valence for atom # 0 N, 4, is greater than permitted
[13:50:01] Explicit valence for atom # 0 N, 4, is greater than permitted
[13:50:01] Explicit valence for atom # 0 N, 4, is greater than permitted
[13:50:01] Explicit valence for atom # 0 N, 4, is greater than permitted
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type     | Params
-----------------------------------
0 | model | DeepDrug | 763 K 
-----------------------------------
763 K     Trainable params
0         Non-trainable params
763 K     Total params
3.055     Total estimated model params size (MB)
Namespace(configfile='./configs/mae_clr_exps/clr_config.yml')
{'dataset': 'DrugBank', 'task': 'binary', 'category': 'DDI', 'entry1_file': './dataset/DrugBank/drug/processed/data.pt', 'entry2_file': './dataset/DrugBank/drug/processed/data.pt', 'entry1_seq_file': './dataset/DrugBank/drug/drug.csv', 'entry2_seq_file': './dataset/DrugBank/drug/drug.csv', 'pair_file': './dataset/DrugBank/binary_1vs1/entry_pairs.csv', 'label_file': './dataset/DrugBank/binary_1vs1/pair_labels.csv', 'save_folder': './output/CLR/DrugBank/binary_1vs1/all_cluster/', 'split_strategy': 'sample_from_all_clusters', 'gconv_ckpt': './model_checkpoints/clr_epoch_20_layers_4_random/last.ckpt', 'lin_eval': False, 'model_type': 'deepdrug', 'gpus': 0, 'num_out_dim': 1, 'n_layers': 4}
print parameters:
{
  "earlystopping_tracking": "val_epoch_F1",
  "entry1_data_folder": "./dataset/DrugBank/drug",
  "entry1_seq_file": "./dataset/DrugBank/drug/drug.csv",
  "entry2_data_folder": "./dataset/DrugBank/drug",
  "entry2_seq_file": "./dataset/DrugBank/drug/drug.csv",
  "entry_pairs_file": "./dataset/DrugBank/binary_1vs1/entry_pairs.csv",
  "gpus": 0,
  "model_type": "deepdrug",
  "pair_labels_file": "./dataset/DrugBank/binary_1vs1/pair_labels.csv",
  "save_folder": "./output/CLR/DrugBank/binary_1vs1/all_cluster/",
  "scheduler_ReduceLROnPlateau_tracking": "F1",
  "split_strat": "sample_from_all_clusters",
  "task_type": "binary",
  "y_pred_file": "./output/CLR/DrugBank/binary_1vs1/all_cluster/test_pred.csv",
  "y_transfrom_func": null,
  "y_true_file": "./output/CLR/DrugBank/binary_1vs1/all_cluster/test_true.csv"
}
DeepDrug(
  (gconv1): DeeperGCN(
    (node_encoder): Sequential(
      (0): Linear(in_features=121, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (gcn_blocks): ModuleList(
      (0): ModuleList(
        (0): DeepGCNLayerV2(block=res+)
        (1): DeepGCNLayerV2(block=res+)
        (2): DeepGCNLayerV2(block=res+)
        (3): DeepGCNLayerV2(block=res+)
      )
    )
    (edge_encoder): Sequential(
      (0): Linear(in_features=11, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (gconv1_seq): CNN(
    (conv): ModuleList(
      (0): Conv1d(67, 32, kernel_size=(4,), stride=(1,))
      (1): Conv1d(32, 64, kernel_size=(6,), stride=(1,))
      (2): Conv1d(64, 96, kernel_size=(8,), stride=(1,))
    )
    (fc1): Linear(in_features=96, out_features=128, bias=True)
  )
  (gconv2): DeeperGCN(
    (node_encoder): Sequential(
      (0): Linear(in_features=121, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (gcn_blocks): ModuleList(
      (0): ModuleList(
        (0): DeepGCNLayerV2(block=res+)
        (1): DeepGCNLayerV2(block=res+)
        (2): DeepGCNLayerV2(block=res+)
        (3): DeepGCNLayerV2(block=res+)
      )
    )
    (edge_encoder): Sequential(
      (0): Linear(in_features=11, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (gconv2_seq): CNN(
    (conv): ModuleList(
      (0): Conv1d(67, 32, kernel_size=(4,), stride=(1,))
      (1): Conv1d(32, 64, kernel_size=(6,), stride=(1,))
      (2): Conv1d(64, 96, kernel_size=(8,), stride=(1,))
    )
    (fc1): Linear(in_features=96, out_features=128, bias=True)
  )
  (global_fc_nn): Sequential(
    (0): Linear(in_features=512, out_features=128, bias=True)
    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=False)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=32, bias=True)
    (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Dropout(p=0.2, inplace=False)
    (7): ReLU()
  )
  (fc2): Linear(in_features=32, out_features=1, bias=True)
)
preparing dataset...
loading processed data...
add degrees as node features for each sample...
using drug sequences file: ./dataset/DrugBank/drug
print save parquet file to load quickly next time at ./dataset/DrugBank/drug/drug.parquet
                                        SMILES                                              entry
drugID                                                                                           
DB04571    CC1=CC2=CC3=C(OC(=O)C=C3C)C(C)=C2O1  [21, 21, 25, 48, 21, 21, 10, 48, 21, 21, 26, 4...
DB00855                        NCC(=O)CCC(O)=O  [30, 21, 21, 55, 48, 64, 24, 21, 21, 21, 55, 6...
DB09536                               O=[Ti]=O  [64, 48, 12, 47, 33, 51, 48, 64, 29, 29, 29, 2...
DB01600  CC(C(O)=O)C1=CC=C(S1)C(=O)C1=CC=CC=C1  [21, 21, 55, 21, 55, 64, 24, 48, 64, 24, 21, 2...
checking entryIDs finished for MultiEmbedDataset_v1.
loading processed data...
add degrees as node features for each sample...
using target sequences file: ./dataset/DrugBank/drug
print save parquet file to load quickly next time at ./dataset/DrugBank/drug/drug.parquet
                                        SMILES                                              entry
drugID                                                                                           
DB04571    CC1=CC2=CC3=C(OC(=O)C=C3C)C(C)=C2O1  [21, 21, 25, 48, 21, 21, 10, 48, 21, 21, 26, 4...
DB00855                        NCC(=O)CCC(O)=O  [30, 21, 21, 55, 48, 64, 24, 21, 21, 21, 55, 6...
DB09536                               O=[Ti]=O  [64, 48, 12, 47, 33, 51, 48, 64, 29, 29, 29, 2...
DB01600  CC(C(O)=O)C1=CC=C(S1)C(=O)C1=CC=CC=C1  [21, 21, 55, 21, 55, 64, 24, 48, 64, 24, 21, 2...
checking entryIDs finished for MultiEmbedDataset_v1.
can not find cv_file,  sample_from_all_clusters ...
0.6327160493827161
0.13407939189189189
0.23320455872539206
Sanity Checking: 0it [00:00, ?it/s]in val dataloader...
Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:11<00:11, 11.73s/it]Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:12<00:00,  6.17s/it]
val:Ep0000|| F1: 0.541,auROC nan,auPRC: 1.000
                                                                           in train dataloader...
Training: 0it [00:00, ?it/s]Training:   0%|          | 0/1150 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1150 [00:00<?, ?it/s] Traceback (most recent call last):
  File "clr_finetuning.py", line 148, in <module>
    trainer.fit(model, datamodule=datamodule,)
  File "/home/s1950841/.conda/envs/masters/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 582, in fit
    call._call_and_handle_interrupt(
  File "/home/s1950841/.conda/envs/masters/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py", line 38, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/s1950841/.conda/envs/masters/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 624, in _fit_impl
    self._run(model, ckpt_path=self.ckpt_path)
  File "/home/s1950841/.conda/envs/masters/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1061, in _run
    results = self._run_stage()
  File "/home/s1950841/.conda/envs/masters/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1140, in _run_stage
    self._run_train()
  File "/home/s1950841/.conda/envs/masters/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1163, in _run_train
    self.fit_loop.run()
  File "/home/s1950841/.conda/envs/masters/lib/python3.8/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
    self.advance(*args, **kwargs)
  File "/home/s1950841/.conda/envs/masters/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py", line 267, in advance
    self._outputs = self.epoch_loop.run(self._data_fetcher)
  File "/home/s1950841/.conda/envs/masters/lib/python3.8/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
    self.advance(*args, **kwargs)
  File "/home/s1950841/.conda/envs/masters/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 188, in advance
    batch = next(data_fetcher)
  File "/home/s1950841/.conda/envs/masters/lib/python3.8/site-packages/pytorch_lightning/utilities/fetching.py", line 184, in __next__
    return self.fetching_function()
  File "/home/s1950841/.conda/envs/masters/lib/python3.8/site-packages/pytorch_lightning/utilities/fetching.py", line 265, in fetching_function
    self._fetch_next_batch(self.dataloader_iter)
  File "/home/s1950841/.conda/envs/masters/lib/python3.8/site-packages/pytorch_lightning/utilities/fetching.py", line 280, in _fetch_next_batch
    batch = next(iterator)
  File "/home/s1950841/.conda/envs/masters/lib/python3.8/site-packages/pytorch_lightning/trainer/supporters.py", line 568, in __next__
    return self.request_next_batch(self.loader_iters)
  File "/home/s1950841/.conda/envs/masters/lib/python3.8/site-packages/pytorch_lightning/trainer/supporters.py", line 580, in request_next_batch
    return apply_to_collection(loader_iters, Iterator, next)
  File "/home/s1950841/.conda/envs/masters/lib/python3.8/site-packages/lightning_utilities/core/apply_func.py", line 47, in apply_to_collection
    return function(data, *args, **kwargs)
  File "/home/s1950841/.conda/envs/masters/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 681, in __next__
    data = self._next_data()
  File "/home/s1950841/.conda/envs/masters/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 721, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/s1950841/.conda/envs/masters/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 49, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/s1950841/.conda/envs/masters/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 49, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/s1950841/MAEDDI/dataset.py", line 511, in __getitem__
    self.entry2[self.entry2_ids.index(tmp2)]),
  File "/home/s1950841/MAEDDI/dataset.py", line 492, in __getitem__
    return [self.datasets[0][idx], self.datasets[1][self.datasets2_idx[idx]]]
  File "/home/s1950841/.conda/envs/masters/lib/python3.8/site-packages/torch_geometric/data/dataset.py", line 263, in __getitem__
    data = self.get(self.indices()[idx])
IndexError: range object index out of range
Epoch 0:   0%|          | 0/1150 [00:00<?, ?it/s]
